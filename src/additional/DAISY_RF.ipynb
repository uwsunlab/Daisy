{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o9O31_iq5DZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "file_path = ''  # Update the path accordingly\n",
        "data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
        "\n",
        "# Strip any leading/trailing whitespace from column names\n",
        "data.columns = data.columns.str.strip()\n"
      ],
      "metadata": {
        "id": "nsyoEsO358ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categorical features for label encoding\n",
        "label_features = [\n",
        "    'Spincoating Speed', 'Antisolvent Used', 'Substrates preheated Temperature',\n",
        "    'Solution preheated temperature'\n",
        "]\n",
        "\n",
        "# Encode categorical variables with NA as a category\n",
        "label_encoders = {}\n",
        "for column in label_features:\n",
        "    data[column] = data[column].fillna('NA')  # Treat NA as a valid category\n",
        "    le = LabelEncoder()\n",
        "    data[column] = le.fit_transform(data[column].astype(str))\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Feature engineering: Polynomial features (optional, based on need)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "poly_features = poly.fit_transform(data[label_features])\n",
        "poly_feature_names = poly.get_feature_names_out(label_features)\n",
        "poly_df = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
        "\n",
        "# Impute missing values in polynomial features (except for specific target columns)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "poly_df_imputed = imputer.fit_transform(poly_df)\n",
        "poly_df = pd.DataFrame(poly_df_imputed, columns=poly_feature_names)\n",
        "\n",
        "# Concatenate polynomial features with original data\n",
        "data = pd.concat([data.reset_index(drop=True), poly_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Define features and targets\n",
        "features = poly_feature_names\n",
        "target_coverage = 'Coverage Percentage'\n",
        "target_avg_size = 'Average Size um'\n",
        "\n",
        "# Drop rows where the target variable is missing\n",
        "data_cov = data.dropna(subset=[target_coverage])\n",
        "data_size = data.dropna(subset=[target_avg_size])  # Do not impute empty cells; just drop\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_cov = data_cov[features]\n",
        "y_cov = data_cov[target_coverage]\n",
        "\n",
        "X_size = data_size[features]\n",
        "y_size = data_size[target_avg_size]\n",
        "\n",
        "X_train_cov, X_test_cov, y_train_cov, y_test_cov = train_test_split(X_cov, y_cov, test_size=0.2, random_state=42)\n",
        "X_train_size, X_test_size, y_train_size, y_test_size = train_test_split(X_size, y_size, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [300, 400, 500],\n",
        "    'max_features': ['log2'],\n",
        "    'max_depth': [None],\n",
        "    'min_samples_split': [10, 15, 20]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV objects for both targets\n",
        "grid_search_cov = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
        "grid_search_size = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
        "\n",
        "# Perform grid search for Coverage Percentage\n",
        "grid_search_cov.fit(X_train_cov, y_train_cov)\n",
        "\n",
        "# Best parameters and model for Coverage Percentage\n",
        "best_rf_cov = grid_search_cov.best_estimator_\n",
        "\n",
        "# Perform grid search for Average Size scaled\n",
        "grid_search_size.fit(X_train_size, y_train_size)\n",
        "\n",
        "# Best parameters and model for Average Size scaled\n",
        "best_rf_size = grid_search_size.best_estimator_\n",
        "\n"
      ],
      "metadata": {
        "id": "LdcmqDQR6HdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the training and test sets\n",
        "y_train_pred_cov = best_rf_cov.predict(X_train_cov)\n",
        "y_test_pred_cov = best_rf_cov.predict(X_test_cov)\n",
        "\n",
        "y_train_pred_size = best_rf_size.predict(X_train_size)\n",
        "y_test_pred_size = best_rf_size.predict(X_test_size)\n",
        "\n",
        "# Calculate RMSE for training and testing sets\n",
        "train_rmse_cov = np.sqrt(mean_squared_error(y_train_cov, y_train_pred_cov))\n",
        "test_rmse_cov = np.sqrt(mean_squared_error(y_test_cov, y_test_pred_cov))\n",
        "\n",
        "train_rmse_size = np.sqrt(mean_squared_error(y_train_size, y_train_pred_size))\n",
        "test_rmse_size = np.sqrt(mean_squared_error(y_test_size, y_test_pred_size))\n",
        "\n",
        "# Save predicted values and actual values for plotting\n",
        "results_cov = {\n",
        "    'y_train_actual': y_train_cov,\n",
        "    'y_train_predicted': y_train_pred_cov,\n",
        "    'y_test_actual': y_test_cov,\n",
        "    'y_test_predicted': y_test_pred_cov,\n",
        "    'train_rmse': train_rmse_cov,\n",
        "    'test_rmse': test_rmse_cov\n",
        "}\n",
        "\n",
        "results_size = {\n",
        "    'y_train_actual': y_train_size,\n",
        "    'y_train_predicted': y_train_pred_size,\n",
        "    'y_test_actual': y_test_size,\n",
        "    'y_test_predicted': y_test_pred_size,\n",
        "    'train_rmse': train_rmse_size,\n",
        "    'test_rmse': test_rmse_size\n",
        "}\n",
        "\n",
        "# Save the results as joblib files for later use\n",
        "joblib.dump(results_cov, 'results_coverage.joblib')\n",
        "joblib.dump(results_size, 'results_size.joblib')\n",
        "\n",
        "print(\"Results saved for parity plot generation.\")\n"
      ],
      "metadata": {
        "id": "SIe5_0gX6K0f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved results\n",
        "results_cov = joblib.load('results_coverage.joblib')\n",
        "results_size = joblib.load('results_size.joblib')\n",
        "\n",
        "def remove_outliers(y_actual, y_predicted, threshold=3):\n",
        "    \"\"\"Remove outliers based on residuals.\"\"\"\n",
        "    residuals = y_actual - y_predicted\n",
        "    z_scores = np.abs((residuals - np.mean(residuals)) / np.std(residuals))\n",
        "    mask = z_scores < threshold\n",
        "    return y_actual[mask], y_predicted[mask]\n",
        "\n",
        "# Remove outliers for Coverage Percentage\n",
        "y_train_cov_actual_filtered, y_train_cov_predicted_filtered = remove_outliers(\n",
        "    results_cov['y_train_actual'], results_cov['y_train_predicted']\n",
        ")\n",
        "y_test_cov_actual_filtered, y_test_cov_predicted_filtered = remove_outliers(\n",
        "    results_cov['y_test_actual'], results_cov['y_test_predicted']\n",
        ")\n",
        "\n",
        "# Parity Plot for Coverage Percentage\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(\n",
        "    y_train_cov_actual_filtered, y_train_cov_predicted_filtered,\n",
        "    color='blue', alpha=0.6,\n",
        "    label=f'Train RMSE: {results_cov[\"train_rmse\"]:.2f}', marker='o'\n",
        ")\n",
        "plt.scatter(\n",
        "    y_test_cov_actual_filtered, y_test_cov_predicted_filtered,\n",
        "    color='red', alpha=0.6,\n",
        "    label=f'Test RMSE: {results_cov[\"test_rmse\"]:.2f}', marker='o'\n",
        ")\n",
        "plt.plot([0, 25], [0, 25], 'k--', lw=2)  # Diagonal line within axis limits\n",
        "plt.xlim(0, 25)  # Set x-axis limits\n",
        "plt.ylim(0, 25)  # Set y-axis limits\n",
        "plt.xlabel('Actual Coverage Percentage')\n",
        "plt.ylabel('Predicted Coverage Percentage')\n",
        "plt.title('Parity Plot - Coverage Percentage (Train vs Test)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Similarly for Average Size Scaled\n",
        "y_train_size_actual_filtered, y_train_size_predicted_filtered = remove_outliers(\n",
        "    results_size['y_train_actual'], results_size['y_train_predicted']\n",
        ")\n",
        "y_test_size_actual_filtered, y_test_size_predicted_filtered = remove_outliers(\n",
        "    results_size['y_test_actual'], results_size['y_test_predicted']\n",
        ")\n",
        "\n",
        "# Parity Plot for Average Size Scaled\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(\n",
        "    y_train_size_actual_filtered, y_train_size_predicted_filtered,\n",
        "    color='blue', alpha=0.6,\n",
        "    label=f'Train RMSE: {results_size[\"train_rmse\"]:.2f}', marker='o'\n",
        ")\n",
        "plt.scatter(\n",
        "    y_test_size_actual_filtered, y_test_size_predicted_filtered,\n",
        "    color='red', alpha=0.6,\n",
        "    label=f'Test RMSE: {results_size[\"test_rmse\"]:.2f}', marker='o'\n",
        ")\n",
        "plt.plot([0, 0.3], [0, 0.3], 'k--', lw=2)  # Diagonal line within axis limits\n",
        "plt.xlim(0, 0.3)  # Set x-axis limits\n",
        "plt.ylim(0, 0.3)  # Set y-axis limits\n",
        "plt.xlabel('Actual Average Size Scaled')\n",
        "plt.ylabel('Predicted Average Size Scaled')\n",
        "plt.title('Parity Plot - Average Size Scaled (Train vs Test)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yAbIB2dT6yYQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
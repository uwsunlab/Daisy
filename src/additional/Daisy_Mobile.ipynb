{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79390,
     "status": "ok",
     "timestamp": 1735686112148,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "A4dICEo5Mocg",
    "outputId": "41f7aecc-232e-4f88-dfd0-fd1180dda0fc"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBH424sh9J1i"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaydCRa79LKo"
   },
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_images_from_folder(folder_path, label, resize=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_resized = img.resize(resize)  # Resize to 224x224\n",
    "            images.append(np.array(img_resized) / 255.0)  # Normalize\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Paths to original HOLES and NO HOLES datasets\n",
    "holes_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/HOLES'  # Replace with your path\n",
    "no_holes_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/NO HOLES'  # Replace with your path\n",
    "\n",
    "# Load HOLES (defect images) and NO HOLES (non-defect images)\n",
    "holes_images, holes_labels = load_images_from_folder(holes_folder, label=1)\n",
    "no_holes_images, no_holes_labels = load_images_from_folder(no_holes_folder, label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1735686272986,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "HNQ3iHQD6fAN",
    "outputId": "04868a7f-3682-4e48-cc2f-db02329ed15d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function to count files in a folder\n",
    "def count_patches_in_folder(folder_path):\n",
    "    patch_count = len([f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg', '.tif'))])\n",
    "    return patch_count\n",
    "\n",
    "# Paths to the patch folders\n",
    "defect_patches_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/defect patches'  # Replace with your path\n",
    "holes_with_patches_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/PATCHES'  # Replace with your path\n",
    "no_holes_with_patches_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/PATCHES_nh'  # Replace with your path\n",
    "\n",
    "# Count patches in each folder\n",
    "defect_patch_count = count_patches_in_folder(defect_patches_folder)\n",
    "holes_patch_count = count_patches_in_folder(holes_with_patches_folder)\n",
    "no_holes_patch_count = count_patches_in_folder(no_holes_with_patches_folder)\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of patches in DEFECT_PATCHES: {defect_patch_count}\")\n",
    "print(f\"Number of patches in HOLES_WITH_PATCHES: {holes_patch_count}\")\n",
    "print(f\"Number of patches in NO_HOLES_WITH_PATCHES: {no_holes_patch_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67262,
     "status": "ok",
     "timestamp": 1735686502578,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "1NnWric5_BTT",
    "outputId": "7e2ed7de-6617-4f00-ef3c-2ee926dc0ee2"
   },
   "outputs": [],
   "source": [
    "# Load patch dataset\n",
    "def load_patches_from_folder(folder_path, label):\n",
    "    patches = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            patches.append(np.array(img) / 255.0)  # Normalize pixel values\n",
    "            labels.append(label)\n",
    "    return patches, labels\n",
    "\n",
    "# Paths to patch folders\n",
    "defect_patches_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/defect patches'  # Replace with your path\n",
    "non_defect_patches_folder_1 = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/PATCHES'  # Replace with your path\n",
    "non_defect_patches_folder_2 = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/PATCHES_nh'  # Replace with your path\n",
    "\n",
    "# Load patches\n",
    "defect_patches, defect_labels = load_patches_from_folder(defect_patches_folder, label=1)\n",
    "non_defect_patches_1, non_defect_labels_1 = load_patches_from_folder(non_defect_patches_folder_1, label=0)\n",
    "non_defect_patches_2, non_defect_labels_2 = load_patches_from_folder(non_defect_patches_folder_2, label=0)\n",
    "\n",
    "# Combine all data (original + patches)\n",
    "all_images = holes_images + no_holes_images + defect_patches + non_defect_patches_1 + non_defect_patches_2\n",
    "all_labels = holes_labels + no_holes_labels + defect_labels + non_defect_labels_1 + non_defect_labels_2\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(all_images)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "print(f\"Total dataset size: {X.shape}, Labels: {y.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1735686512138,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "79ajxj-F_i81",
    "outputId": "148351ee-02bd-4b06-ec81-c770d99884b1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% train, 20% temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # Split temp into 10% val, 10% test\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23155,
     "status": "ok",
     "timestamp": 1735686689508,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "1K7lCWnMQq73",
    "outputId": "c2cdb918-34e1-465e-c475-c885975771f2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load pre-trained VGG16\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  # Dropout regularization\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train only the custom layers\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=15,  # Start with a few epochs\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63808,
     "status": "ok",
     "timestamp": 1735686764956,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "8pbEtuUZTBou",
    "outputId": "62f75397-7b68-4668-8d9c-22bf1388d947"
   },
   "outputs": [],
   "source": [
    "# Unfreeze all layers for fine-tuning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler and early stopping\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Fine-tune the entire model\n",
    "fine_tune_history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    callbacks=[lr_scheduler, early_stopping],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1315,
     "status": "ok",
     "timestamp": 1735686768259,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "mDdq8hTFVDuY",
    "outputId": "7719f6fe-6375-4e63-9719-9c32bcfc1cef"
   },
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1735686783413,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "zvsIqbfTVF97",
    "outputId": "239a6c21-3bef-402e-dc1e-b1a225337389"
   },
   "outputs": [],
   "source": [
    "# Accuracy plot\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(fine_tune_history.history['accuracy'], label='Fine-Tune Training Accuracy')\n",
    "plt.plot(fine_tune_history.history['val_accuracy'], label='Fine-Tune Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training vs. Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Loss plot\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(fine_tune_history.history['loss'], label='Fine-Tune Training Loss')\n",
    "plt.plot(fine_tune_history.history['val_loss'], label='Fine-Tune Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "executionInfo": {
     "elapsed": 3493,
     "status": "ok",
     "timestamp": 1735686789590,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "XGlcYPUxVLW9",
    "outputId": "1eb7bb38-bc16-4479-e1ac-5a45235b0daf"
   },
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Defect', 'Defect'], yticklabels=['Non-Defect', 'Defect'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Test Set)')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Non-Defect', 'Defect']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "executionInfo": {
     "elapsed": 3259,
     "status": "ok",
     "timestamp": 1735686812007,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "fni6NCHpVUgE",
    "outputId": "f46fdd78-25cd-4c22-ee95-b43b57158a0e"
   },
   "outputs": [],
   "source": [
    "# Predict on the training set\n",
    "y_train_pred = (model.predict(X_train) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Defect', 'Defect'], yticklabels=['Non-Defect', 'Defect'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Training Set)')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report (Training Set):\")\n",
    "print(classification_report(y_train, y_train_pred, target_names=['Non-Defect', 'Defect']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "executionInfo": {
     "elapsed": 1830,
     "status": "ok",
     "timestamp": 1735686838476,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "8mp8uhfi_v6I",
    "outputId": "cd3a7a80-1cee-44b1-971e-0a711783320e"
   },
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "y_val_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Defect', 'Defect'], yticklabels=['Non-Defect', 'Defect'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Validation Set)')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report (Validation Set):\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=['Non-Defect', 'Defect']))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1B_DIql5UvwWYyfGvzbsyE_kij1Y2KsIG",
     "timestamp": 1734695943668
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

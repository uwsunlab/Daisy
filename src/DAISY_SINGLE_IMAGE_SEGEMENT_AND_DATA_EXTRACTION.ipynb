{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM8Iw0lKvsT3tzcASP3KdK+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## MOUNTING GOOGLE DRIVE"],"metadata":{"id":"whMGzS3cmPr-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0NUOIWKGyiBR"},"outputs":[],"source":["using_colab = True\n","from google.colab import drive\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## INSTALL SEGMENT ANYTHING MODEL"],"metadata":{"id":"GzHQYjC_mTn1"}},{"cell_type":"code","source":["if using_colab:\n","    import torch\n","    import torchvision\n","    print(\"PyTorch version:\", torch.__version__)\n","    print(\"Torchvision version:\", torchvision.__version__)\n","    print(\"CUDA is available:\", torch.cuda.is_available())\n","    import sys\n","    !{sys.executable} -m pip install opencv-python matplotlib\n","    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n","\n","    !mkdir images\n","    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n","    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth"],"metadata":{"id":"BhvwbFmLyn2X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## INSTALL LIBRARIES"],"metadata":{"id":"U7GJTY4Xmd5E"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import cv2"],"metadata":{"id":"fr78HTkoysVB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CALL AND DISPLAY IMAGE"],"metadata":{"id":"CYudeYjRmiqB"}},{"cell_type":"code","source":["image = cv2.imread('')# add your path here\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"],"metadata":{"id":"dSmtOuoDy-FG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dpi = 100\n","fig_width = 1024 / dpi  # 10.24 inches\n","fig_height = 691 / dpi  # 6.91 inches\n","\n","plt.figure(figsize=(fig_width, fig_height), dpi=dpi)\n","plt.imshow(image)\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"63wkmDEozL3t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SETUP SAM"],"metadata":{"id":"VYw1IaH5mooA"}},{"cell_type":"code","source":["import sys\n","sys.path.append(\"..\")\n","from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n","\n","sam_checkpoint = \"sam_vit_l_0b3195.pth\"\n","model_type = \"vit_l\"\n","\n","device = torch.device(\"cuda\") ## change to cpu if no gpu available\n","\n","sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n","sam.to(device=device)\n","\n","mask_generator = SamAutomaticMaskGenerator(sam)"],"metadata":{"id":"1fKQCenPzO6t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DISPLAYING IMAGES WITH THE SEGMENTED IMAGE MASKS"],"metadata":{"id":"_PlCfW2RmuU3"}},{"cell_type":"code","source":["def show_anns(anns):\n","    if len(anns) == 0:\n","        return\n","    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n","    ax = plt.gca()\n","    ax.set_autoscale_on(False)\n","\n","    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n","    img[:,:,3] = 0\n","    for ann in sorted_anns:\n","        m = ann['segmentation']\n","        color_mask = np.concatenate([np.random.random(3), [0.35]])\n","        img[m] = color_mask\n","    ax.imshow(img)"],"metadata":{"id":"nRPCWAGcyuXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["masks = mask_generator.generate(image)\n","print(len(masks))\n","print(masks[0].keys())\n","dpi = 100\n","fig_width = 1024 / dpi  # 10.24 inches\n","fig_height = 691 / dpi  # 6.91 inches\n","\n","plt.figure(figsize=(fig_width, fig_height), dpi=dpi)\n","plt.imshow(image)\n","show_anns(masks)\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"PTqxyJZ2zYLl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mask_generator_2 = SamAutomaticMaskGenerator(\n","    model=sam,\n","    points_per_side=52,\n","    pred_iou_thresh=0.7,\n","    stability_score_thresh=0.92,\n","    crop_n_layers=1,\n","    crop_n_points_downscale_factor=2,\n","    min_mask_region_area=60,  # Requires open-cv to run post-processing\n",")\n","\n","masks2 = mask_generator_2.generate(image)\n","len(masks2)\n","\n","dpi = 100\n","fig_width = 1024 / dpi  # 10.24 inches\n","fig_height = 691 / dpi  # 6.91 inches\n","\n","plt.figure(figsize=(fig_width, fig_height), dpi=dpi)\n","plt.imshow(image)\n","show_anns(masks2)\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"d7wPzAiizcK2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SETUP CLUSTERING AND APPLY CLUSTERING"],"metadata":{"id":"GTa7ePm7m5QF"}},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","from sklearn.cluster import KMeans\n","import matplotlib.pyplot as plt\n","\n","def filter_masks_by_size(masks, image, max_size):\n","    \"\"\"\n","    Filters masks based on their size to remove very small and very large masks.\n","    min_size and max_size should be defined based on the domain knowledge about the grain sizes.\n","    \"\"\"\n","    filtered_masks = []\n","    total_pixels = image.shape[0] * image.shape[1]\n","    for mask in masks:\n","        mask_size = np.sum(mask['segmentation'])\n","        if mask_size <= max_size:\n","            filtered_masks.append(mask)\n","    return filtered_masks\n","\n","def calculate_circularity(mask):\n","    area = np.sum(mask)\n","    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    if contours:\n","        perimeter = cv2.arcLength(contours[0], True)\n","        if perimeter == 0:\n","            return 0\n","        circularity = 4 * np.pi * (area / (perimeter ** 2))\n","    else:\n","        circularity = 0\n","    return circularity\n","def average_intensity(image, mask):\n","    masked_image = cv2.bitwise_and(image, image, mask=mask.astype(np.uint8))\n","    return np.mean(masked_image[mask > 0])\n","\n","def calculate_iou(mask1, mask2):\n","    intersection = np.logical_and(mask1, mask2)\n","    union = np.logical_or(mask1, mask2)\n","    iou = np.sum(intersection) / np.sum(union)\n","    return iou\n","\n","def apply_kmeans(masks, image):\n","    avg_intensities = [average_intensity(image, mask['segmentation']) for mask in masks]\n","    features = np.array(avg_intensities).reshape(-1, 1)\n","    kmeans = KMeans(n_clusters=2, random_state=0).fit(features)\n","    labels = kmeans.labels_\n","    cluster_centers = kmeans.cluster_centers_\n","    darker_cluster_index = 0 if cluster_centers[0] < cluster_centers[1] else 1\n","    darker_masks = [masks[i] for i in range(len(masks)) if labels[i] == darker_cluster_index]\n","    lighter_masks = [masks[i] for i in range(len(masks)) if labels[i] != darker_cluster_index]\n","    return darker_masks,lighter_masks\n","\n","\n","\n","def show_masks(image, masks,title=\"Masks\"):\n","    plt.figure(figsize=(20, 20))\n","    plt.imshow(image)\n","    show_anns(masks)\n","    plt.title(title)\n","    plt.axis('off')\n","    plt.show()\n","\n","def resolve_overlaps(masks):\n","    keep_masks = []\n","    n = len(masks)\n","    removed = set()\n","\n","    for i in range(n):\n","        if i in removed:\n","            continue\n","        current_mask = masks[i]['segmentation']\n","        max_area = np.sum(current_mask)\n","        best_mask = masks[i]\n","\n","        for j in range(i + 1, n):\n","            if j in removed:\n","                continue\n","            compare_mask = masks[j]['segmentation']\n","            if calculate_iou(current_mask, compare_mask) > 0.5:  # Threshold for considering an overlap\n","                if np.sum(compare_mask) > max_area:\n","                    max_area = np.sum(compare_mask)\n","                    removed.add(i)\n","                    best_mask = masks[j]\n","                    current_mask = compare_mask\n","                else:\n","                    removed.add(j)\n","\n","        keep_masks.append(best_mask)\n","\n","    return keep_masks\n","\n","\n","\n","\n","\n","# Assuming masks and image are defined\n","darker_masks1, lighter_masks1 = apply_kmeans(masks, image)\n","darker_masks2, lighter_masks2 = apply_kmeans(masks2, image)\n","# Combine and resolve overlaps for darker masks\n","combined_darker_masks =  darker_masks2\n","non_overlapping_darker = resolve_overlaps(combined_darker_masks)\n","show_masks(image, combined_darker_masks, \"Darker Masks\")\n","\n","# Calculate and display properties for lighter masks\n","combined_lighter_masks =  lighter_masks2\n","non_overlapping_lighter = resolve_overlaps(combined_lighter_masks)\n","max_size = 0.1 * image.shape[0] * image.shape[1]   # Example: 10% of the image area\n","filtered_lighter_masks = filter_masks_by_size(combined_lighter_masks, image, max_size)\n","show_masks(image, filtered_lighter_masks, \"Lighter Masks\")\n","\n"],"metadata":{"id":"fXu_teBZ1P8z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## EXTRACT GRAIN AREAS AND DISPLAY DISTRIBUTION GRAPH"],"metadata":{"id":"9pR27sApnL7G"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import altair as alt\n","\n","def extract_and_print_areas(masks, pixel_to_um_scale):\n","    \"\"\"\n","    Extracts areas from masks, converts them to µm², and prints them.\n","    \"\"\"\n","    areas_pixels = [mask['area'] for mask in masks]\n","    areas_um2 = [area * pixel_to_um_scale for area in areas_pixels]\n","    average_area_pixels = np.mean(areas_pixels) if areas_pixels else 0\n","    average_area_um2 = np.mean(areas_um2) if areas_um2 else 0\n","\n","    print(\"Number of masks:\", len(masks))\n","    print(\"Areas of all masks in pixels:\", areas_pixels)\n","    print(\"Areas of all masks in µm²:\", areas_um2)\n","    print(f\"Average area of masks: {average_area_pixels:.2f} pixels\")\n","    print(f\"Average area of masks: {average_area_um2:.2f} µm²\")\n","\n","    return areas_um2  # Return areas in µm² for further processing\n","\n","def remove_outliers(data, lower_percentile=25, upper_percentile=75, factor=1.5):\n","    \"\"\"\n","    Removes outliers from data based on the IQR method.\n","    \"\"\"\n","    q1 = np.percentile(data, lower_percentile)\n","    q3 = np.percentile(data, upper_percentile)\n","    iqr = q3 - q1\n","    lower_bound = q1 - (factor * iqr)\n","    upper_bound = q3 + (factor * iqr)\n","\n","    return [x for x in data if lower_bound <= x <= upper_bound]\n","\n","def plot_distribution_areas(areas_um2):\n","    \"\"\"\n","    Plots the distribution of areas without outliers using Altair.\n","    \"\"\"\n","    # Remove outliers\n","    areas_um2_filtered = remove_outliers(areas_um2)\n","\n","    # Convert the filtered areas to a DataFrame\n","    data = pd.DataFrame({'Area_um2': areas_um2_filtered})\n","\n","    # Create the distribution bar chart without normalization and without outliers\n","    bar_chart = alt.Chart(data).mark_bar().encode(\n","        alt.X('Area_um2:Q', bin=alt.Bin(maxbins=100), axis=alt.Axis(labelAngle=90, format='.3f')),  # Set more significant digits and vertical labels\n","        alt.Y('count()'),\n","    ).properties(\n","        width=500,\n","        height=300,\n","        title='Distribution of Grain Areas'\n","    ).configure_axis(\n","        labelFont='Arial',\n","        labelFontSize=7,\n","        titleFont='Arial',\n","        titleFontSize=7\n","    ).configure_title(\n","        font='Arial',\n","        fontSize=7\n","    )\n","\n","    return bar_chart\n","\n","# Assuming your `masks` and `filtered_lighter_masks` are already defined from earlier in the code.\n","# Scale factor for converting pixel area to square micrometers (µm²)\n","scale = ## please add the conversion scale\n","pixel_to_um_scale = (scale)** 2\n","\n","# Extract and print areas for lighter masks\n","print(\"Lighter Masks:\")\n","areas_lighter_um2 = extract_and_print_areas(filtered_lighter_masks, pixel_to_um_scale)\n","\n","# Plot distribution for lighter masks without normalization and with outliers removed\n","chart_lighter = plot_distribution_areas(areas_lighter_um2)\n","chart_lighter.display()\n"],"metadata":{"id":"_mq9S1bf1kn0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GRAIN EXTRACTION AND DISTRIBUTION CHART FOR NON DEFECT SAMPLES"],"metadata":{"id":"9b-nb0AQocDG"}},{"cell_type":"code","source":["def filter_masks_by_size(masks, image, max_size):\n","    \"\"\"\n","    Filters masks based on their size to remove very small and very large masks.\n","    \"\"\"\n","    filtered_masks = []\n","    total_pixels = image.shape[0] * image.shape[1]\n","    for mask in masks:\n","        mask_size = np.sum(mask['segmentation'])\n","        if mask_size <= max_size:\n","            filtered_masks.append(mask)\n","    return filtered_masks\n","\n","def calculate_circularity(mask):\n","    area = np.sum(mask)\n","    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    if contours:\n","        perimeter = cv2.arcLength(contours[0], True)\n","        if perimeter == 0:\n","            return 0\n","        circularity = 4 * np.pi * (area / (perimeter ** 2))\n","    else:\n","        circularity = 0\n","    return circularity\n","\n","def average_intensity(image, mask):\n","    masked_image = cv2.bitwise_and(image, image, mask=mask.astype(np.uint8))\n","    return np.mean(masked_image[mask > 0])\n","\n","def calculate_iou(mask1, mask2):\n","    intersection = np.logical_and(mask1, mask2)\n","    union = np.logical_or(mask1, mask2)\n","    iou = np.sum(intersection) / np.sum(union)\n","    return iou\n","\n","def show_masks(image, masks, title=\"Masks\"):\n","    plt.figure(figsize=(20, 20))\n","    plt.imshow(image)\n","    show_anns(masks)\n","    plt.title(title)\n","    plt.axis('off')\n","    plt.show()\n","\n","def resolve_overlaps(masks):\n","    keep_masks = []\n","    n = len(masks)\n","    removed = set()\n","\n","    for i in range(n):\n","        if i in removed:\n","            continue\n","        current_mask = masks[i]['segmentation']\n","        max_area = np.sum(current_mask)\n","        best_mask = masks[i]\n","\n","        for j in range(i + 1, n):\n","            if j in removed:\n","                continue\n","            compare_mask = masks[j]['segmentation']\n","            if calculate_iou(current_mask, compare_mask) > 0.5:  # Threshold for considering an overlap\n","                if np.sum(compare_mask) > max_area:\n","                    max_area = np.sum(compare_mask)\n","                    removed.add(i)\n","                    best_mask = masks[j]\n","                    current_mask = compare_mask\n","                else:\n","                    removed.add(j)\n","\n","        keep_masks.append(best_mask)\n","\n","    return keep_masks\n","\n","# Assuming masks and masks2 are defined\n","# Merge masks from both sources\n","combined_masks =  masks2\n","\n","# Resolve overlaps for combined masks\n","#non_overlapping_masks = resolve_overlaps(combined_masks)\n","\n","# Show resolved masks\n","show_masks(image, combined_masks, \"Resolved Masks\")\n","\n","# Filter lighter masks by size (optional, based on domain knowledge)\n","max_size = 0.1 * image.shape[0] * image.shape[1]   # Example: 10% of the image area\n","filtered_masks = filter_masks_by_size(combined_masks, image, max_size)\n","\n","# Display the filtered masks\n","show_masks(image, filtered_masks, \"Filtered Masks\")"],"metadata":{"id":"4qn7vBGB24X_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import altair as alt\n","def extract_and_print_areas(masks, pixel_to_um_scale):\n","    \"\"\"\n","    Extracts areas from masks, converts them to µm², and prints them.\n","    \"\"\"\n","    areas_pixels = [mask['area'] for mask in masks]\n","    areas_um2 = [area * pixel_to_um_scale for area in areas_pixels]\n","    average_area_pixels = np.mean(areas_pixels) if areas_pixels else 0\n","    average_area_um2 = np.mean(areas_um2) if areas_um2 else 0\n","\n","    print(\"Number of masks:\", len(masks))\n","    print(\"Areas of all masks in pixels:\", areas_pixels)\n","    print(\"Areas of all masks in µm²:\", areas_um2)\n","    print(f\"Average area of masks: {average_area_pixels:.2f} pixels\")\n","    print(f\"Average area of masks: {average_area_um2:.2f} µm²\")\n","\n","    return areas_um2  # Return areas in µm² for further processing\n","\n","def remove_outliers(data, lower_percentile=25, upper_percentile=75, factor=1.5):\n","    \"\"\"\n","    Removes outliers from data based on the IQR method.\n","    \"\"\"\n","    q1 = np.percentile(data, lower_percentile)\n","    q3 = np.percentile(data, upper_percentile)\n","    iqr = q3 - q1\n","    lower_bound = q1 - (factor * iqr)\n","    upper_bound = q3 + (factor * iqr)\n","\n","    return [x for x in data if lower_bound <= x <= upper_bound]\n","\n","def plot_distribution_areas(areas_um2):\n","    \"\"\"\n","    Plots the distribution of areas without outliers using Altair.\n","    \"\"\"\n","    # Remove outliers\n","    areas_um2_filtered = remove_outliers(areas_um2)\n","\n","    # Convert the filtered areas to a DataFrame\n","    data = pd.DataFrame({'Area_um2': areas_um2_filtered})\n","\n","    # Create the distribution bar chart without normalization and without outliers\n","    bar_chart = alt.Chart(data).mark_bar().encode(\n","        alt.X('Area_um2:Q', bin=alt.Bin(maxbins=100), axis=alt.Axis(labelAngle=90, format='.3f')),  # Set more significant digits and vertical labels\n","        alt.Y('count()'),\n","    ).properties(\n","        width=500,\n","        height=300,\n","        title='Distribution of Grain Areas'\n","    ).configure_axis(\n","        labelFont='Arial',\n","        labelFontSize=7,\n","        titleFont='Arial',\n","        titleFontSize=7\n","    ).configure_title(\n","        font='Arial',\n","        fontSize=7\n","    )\n","\n","    return bar_chart\n","\n","# Assuming your `filtered_masks` are already defined from earlier in the code.\n","# Scale factor for converting pixel area to square micrometers (µm²)\n","scale = ## please add the conversion scale\n","pixel_to_um_scale = scale** 2\n","\n","# Extract and print areas for filtered masks\n","print(\"Filtered Masks:\")\n","areas_filtered_um2 = extract_and_print_areas(filtered_masks, pixel_to_um_scale)\n","\n","# Plot distribution for filtered masks without normalization and with outliers removed\n","chart_filtered = plot_distribution_areas(areas_filtered_um2)\n","chart_filtered.display()\n","\n","\n"],"metadata":{"id":"mQ_SgJsS2_9O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SEGMENT AND DISPLAY MASK IN SAME COLOR"],"metadata":{"id":"YB7bueedoleE"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","def show_anns(anns, color):\n","    if len(anns) == 0:\n","        return\n","    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n","    ax = plt.gca()\n","    ax.set_autoscale_on(False)\n","\n","    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n","    img[:,:,3] = 0\n","    for ann in sorted_anns:\n","        m = ann['segmentation']\n","        color_mask = np.concatenate([color, [0.35]])  # Use the provided color\n","        img[m] = color_mask\n","    ax.imshow(img)\n","\n","# image = cv2.imread('/content/drive/MyDrive/HOLE_Detection/Antisolvent_none_2_8.jpg')\n","image = cv2.imread('/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/NO HOLES/Temp 50-150_150c1.tif')\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","dpi = 100\n","fig_width = 1024 / dpi  # 10.24 inches\n","fig_height = 691 / dpi  # 6.91 inches\n","\n","plt.figure(figsize=(fig_width, fig_height), dpi=dpi)\n","plt.imshow(image)\n","plt.axis('off')\n","plt.show()\n","\n","import sys\n","sys.path.append(\"..\")\n","from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n","\n","sam_checkpoint = \"sam_vit_l_0b3195.pth\"\n","model_type = \"vit_l\"\n","\n","device = torch.device(\"cuda\")\n","\n","sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n","sam.to(device=device)\n","\n","mask_generator = SamAutomaticMaskGenerator(sam)\n","\n","masks = mask_generator.generate(image)\n","\n","# Define the color for masks (e.g., red)\n","mask_color = [1, 0, 0]  # Red color (R, G, B)\n","dpi = 100\n","fig_width = 1024 / dpi  # 10.24 inches\n","fig_height = 691 / dpi  # 6.91 inches\n","\n","plt.figure(figsize=(fig_width, fig_height), dpi=dpi)\n","plt.imshow(image)\n","show_anns(masks, mask_color)\n","plt.axis('off')\n","plt.show()\n","\n","mask_generator_2 = SamAutomaticMaskGenerator(\n","    model=sam,\n","    points_per_side=52,\n","    pred_iou_thresh=0.7,\n","    stability_score_thresh=0.92,\n","    crop_n_layers=1,\n","    crop_n_points_downscale_factor=2,\n","    min_mask_region_area=60,  # Requires open-cv to run post-processing\n",")\n","\n","# Generate second set of masks (masks2)\n","masks2 = mask_generator_2.generate(image)\n","\n","# Define the color for masks2 (e.g., blue)\n","masks2_color = [0, 0, 1]  # Blue color (R, G, B)\n","\n","dpi = 100\n","fig_width = 1024 / dpi  # 10.24 inches\n","fig_height = 691 / dpi  # 6.91 inches\n","\n","plt.figure(figsize=(fig_width, fig_height), dpi=dpi)\n","plt.imshow(image)\n","show_anns(masks2, masks2_color)  # Use masks2_color for the second set of masks\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"GCBQzCSi2uRk"},"execution_count":null,"outputs":[]}]}
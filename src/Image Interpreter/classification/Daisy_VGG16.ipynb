{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25187,
     "status": "ok",
     "timestamp": 1735606067267,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "A4dICEo5Mocg",
    "outputId": "3aeee6b5-4cb5-45c0-c751-bcef0319eda3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3844,
     "status": "ok",
     "timestamp": 1735606083557,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "HNQ3iHQD6fAN",
    "outputId": "c9dae0d1-5bb8-4194-cb03-35778d048ba8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function to count files in a folder\n",
    "def count_patches_in_folder(folder_path):\n",
    "    patch_count = len([f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg', '.tif'))])\n",
    "    return patch_count\n",
    "\n",
    "# Paths to the patch folders\n",
    "defect_patches_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/defect patches'  # Replace with your path\n",
    "holes_with_patches_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/PATCHES'  # Replace with your path\n",
    "no_holes_with_patches_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/PATCHES_nh'  # Replace with your path\n",
    "\n",
    "# Count patches in each folder\n",
    "defect_patch_count = count_patches_in_folder(defect_patches_folder)\n",
    "holes_patch_count = count_patches_in_folder(holes_with_patches_folder)\n",
    "no_holes_patch_count = count_patches_in_folder(no_holes_with_patches_folder)\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of patches in DEFECT_PATCHES: {defect_patch_count}\")\n",
    "print(f\"Number of patches in HOLES_WITH_PATCHES: {holes_patch_count}\")\n",
    "print(f\"Number of patches in NO_HOLES_WITH_PATCHES: {no_holes_patch_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY7ITsKxJ5tv"
   },
   "source": [
    "## VGG 16 fine tuned with full dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NflbhRrPypgx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGMfvQBvys5X"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images_from_folder(folder_path, label, resize=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_resized = img.resize(resize)  # Resize to 224x224\n",
    "            images.append(np.array(img_resized) / 255.0)  # Normalize\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Paths to original HOLES and NO HOLES datasets\n",
    "holes_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/HOLES'  # Replace with your path\n",
    "no_holes_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/NO HOLES'  # Replace with your path\n",
    "\n",
    "# Load HOLES (defect images) and NO HOLES (non-defect images)\n",
    "holes_images, holes_labels = load_images_from_folder(holes_folder, label=1)\n",
    "no_holes_images, no_holes_labels = load_images_from_folder(no_holes_folder, label=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20272,
     "status": "ok",
     "timestamp": 1735606285187,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "yLnv41z13tiD",
    "outputId": "51150d06-f8e0-482f-b362-e300d1ca5756"
   },
   "outputs": [],
   "source": [
    "# Load patch dataset\n",
    "def load_patches_from_folder(folder_path, label):\n",
    "    patches = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            patches.append(np.array(img) / 255.0)  # Normalize pixel values\n",
    "            labels.append(label)\n",
    "    return patches, labels\n",
    "\n",
    "# Paths to patch folders\n",
    "defect_patches_folder = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/defect patches'  # Replace with your path\n",
    "non_defect_patches_folder_1 = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/PATCHES'  # Replace with your path\n",
    "non_defect_patches_folder_2 = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/PATCHES_nh'  # Replace with your path\n",
    "\n",
    "# Load patches\n",
    "defect_patches, defect_labels = load_patches_from_folder(defect_patches_folder, label=1)\n",
    "non_defect_patches_1, non_defect_labels_1 = load_patches_from_folder(non_defect_patches_folder_1, label=0)\n",
    "non_defect_patches_2, non_defect_labels_2 = load_patches_from_folder(non_defect_patches_folder_2, label=0)\n",
    "\n",
    "# Combine all data (original + patches)\n",
    "all_images = holes_images + no_holes_images + defect_patches + non_defect_patches_1 + non_defect_patches_2\n",
    "all_labels = holes_labels + no_holes_labels + defect_labels + non_defect_labels_1 + non_defect_labels_2\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(all_images)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "print(f\"Total dataset size: {X.shape}, Labels: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1123,
     "status": "ok",
     "timestamp": 1735606288727,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "2bp5oCEw3xJY",
    "outputId": "c039e44a-f62d-45cd-e325-d2cdbc60bbc6"
   },
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42468,
     "status": "ok",
     "timestamp": 1732698501768,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 420
    },
    "id": "YvIib2qO36RL",
    "outputId": "ad8bf9e0-3350-49cd-a4a3-0cf45625c869"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load pre-trained VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  # Dropout regularization\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train only the custom layers\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=15,  # Start with a few epochs\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79084,
     "status": "ok",
     "timestamp": 1732698602608,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 420
    },
    "id": "wGeOAAZP4Eu0",
    "outputId": "0a487309-3385-437e-d844-b89229ee342c"
   },
   "outputs": [],
   "source": [
    "# Unfreeze all layers for fine-tuning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler and early stopping\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Fine-tune the entire model\n",
    "fine_tune_history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    callbacks=[lr_scheduler, early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1732698621682,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 420
    },
    "id": "QoQGp2I34UbE",
    "outputId": "2256b9ac-9dc2-4d73-8cf2-eab4a2e19591"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1732698689098,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 420
    },
    "id": "RWG74pU24sIj",
    "outputId": "79b5b6b5-8c4f-424e-ad1e-bf422b1db902"
   },
   "outputs": [],
   "source": [
    "# Accuracy plot\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(fine_tune_history.history['accuracy'], label='Fine-Tune Training Accuracy')\n",
    "plt.plot(fine_tune_history.history['val_accuracy'], label='Fine-Tune Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training vs. Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Loss plot\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(fine_tune_history.history['loss'], label='Fine-Tune Training Loss')\n",
    "plt.plot(fine_tune_history.history['val_loss'], label='Fine-Tune Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5091,
     "status": "ok",
     "timestamp": 1735606345157,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "j3--G94GMv1R",
    "outputId": "5ebc0d45-6e4b-4102-e75d-464b79f65a7e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model_path = '/content/drive/MyDrive/DAISY2.0 Data/vgg16_finetuned_model_daisy_v2.h5'\n",
    "model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "executionInfo": {
     "elapsed": 10288,
     "status": "ok",
     "timestamp": 1735606358227,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "dpmYW8qC48se",
    "outputId": "9ad64329-5a2f-4bf1-dcbe-0ec0ea4e6726"
   },
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Defect', 'Defect'], yticklabels=['Non-Defect', 'Defect'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Test Set)')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Non-Defect', 'Defect']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "executionInfo": {
     "elapsed": 4349,
     "status": "ok",
     "timestamp": 1735606369748,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "Z8P_0vax5Dxj",
    "outputId": "801e1ba4-6212-43f6-87d3-9b42669380c5"
   },
   "outputs": [],
   "source": [
    "# Predict on the training set\n",
    "y_train_pred = (model.predict(X_train) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Defect', 'Defect'], yticklabels=['Non-Defect', 'Defect'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Training Set)')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report (Training Set):\")\n",
    "print(classification_report(y_train, y_train_pred, target_names=['Non-Defect', 'Defect']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "executionInfo": {
     "elapsed": 3600,
     "status": "ok",
     "timestamp": 1735606522661,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "8KUdvAlpM5OS",
    "outputId": "84ddf36a-9140-4709-87fd-98944aa6f291"
   },
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "y_val_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Defect', 'Defect'], yticklabels=['Non-Defect', 'Defect'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Validation Set)')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report (Validation Set):\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=['Non-Defect', 'Defect']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1732698808742,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 420
    },
    "id": "g2iD9nIz5IDU",
    "outputId": "0efaf30e-dfb8-422b-fb3b-cef6528b16d8"
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('/content/drive/MyDrive/DAISY2.0 Data/vgg16_finetuned_model_daisy_v2.h5')\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3327,
     "status": "ok",
     "timestamp": 1732698849581,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 420
    },
    "id": "JVrBcsbD5Z35",
    "outputId": "35877247-22ae-4c74-b5d4-0a67a6335ec7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model_path = '/content/drive/MyDrive/DAISY2.0 Data/vgg16_finetuned_model_daisy_v2.h5'\n",
    "model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5487,
     "status": "ok",
     "timestamp": 1732698926803,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 420
    },
    "id": "WgfTX11S5tCG",
    "outputId": "5b0b43b8-42d0-41fb-f0b3-955cf1042021"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to preprocess a patch\n",
    "def preprocess_patch(patch_path):\n",
    "    patch = Image.open(patch_path).convert('RGB')\n",
    "    patch_resized = patch.resize((224, 224))  # Resize to match model input\n",
    "    patch_array = np.array(patch_resized) / 255.0  # Normalize pixel values\n",
    "    return np.expand_dims(patch_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Function to classify patches in a folder\n",
    "def classify_patches_in_folder(folder_path, model):\n",
    "    defect_count = 0\n",
    "    total_patches = 0\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "            patch_path = os.path.join(folder_path, filename)\n",
    "            patch_array = preprocess_patch(patch_path)\n",
    "\n",
    "            # Predict the class\n",
    "            prediction = model.predict(patch_array)\n",
    "\n",
    "            # Count as defect if prediction > 0.5\n",
    "            if prediction > 0.5:\n",
    "                defect_count += 1\n",
    "\n",
    "            total_patches += 1\n",
    "\n",
    "    return defect_count, total_patches\n",
    "\n",
    "# Path to the folder containing patches\n",
    "folder_path = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/NO HOLES'  # Replace with your folder path\n",
    "\n",
    "# Classify patches and count defects\n",
    "defect_count, total_patches = classify_patches_in_folder(folder_path, model)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of patches classified as defects: {defect_count} out of {total_patches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 989,
     "status": "ok",
     "timestamp": 1732584946883,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "it3Uq-KYF7OY",
    "outputId": "116576e5-cb8a-405b-87a3-f5c198b4d782"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Path to the patch image\n",
    "patch_path = '/content/drive/MyDrive/DAISY2.0 Data/DEC_data_cropped/defect patches/Composition_Ag3BiI6st8_patch_7.png'  # Replace with your patch path\n",
    "\n",
    "# Load and preprocess the patch\n",
    "patch = Image.open(patch_path).convert('RGB')\n",
    "patch_resized = patch.resize((224, 224))  # Resize to match model input\n",
    "patch_array = np.array(patch_resized) / 255.0  # Normalize pixel values\n",
    "patch_array = np.expand_dims(patch_array, axis=0)  # Add batch dimension\n",
    "\n",
    "print(\"Patch preprocessed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1732584949403,
     "user": {
      "displayName": "Kshithij MN",
      "userId": "16083668912830018057"
     },
     "user_tz": 480
    },
    "id": "rkoCiHJ8GbZ_",
    "outputId": "261c6098-fc07-4076-802b-1205e29f4eb6"
   },
   "outputs": [],
   "source": [
    "# Predict the class (0: Non-Defect, 1: Defect)\n",
    "prediction = model.predict(patch_array)\n",
    "\n",
    "# Interpret the result\n",
    "if prediction > 0.5:\n",
    "    print(f\"The patch is classified as: Defect ({prediction[0][0]:.2f})\")\n",
    "else:\n",
    "    print(f\"The patch is classified as: Non-Defect ({prediction[0][0]:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
